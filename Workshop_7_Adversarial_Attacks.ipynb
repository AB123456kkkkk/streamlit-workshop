{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AB123456kkkkk/streamlit-workshop/blob/main/Workshop_7_Adversarial_Attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This workshop is based on an original notebook here: https://savan77.github.io/blog/imagenet_adv_examples.html"
      ],
      "metadata": {
        "id": "oLtNYpQooUpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Installation & Setup"
      ],
      "metadata": {
        "id": "zJEfjYraqYr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the code blocks in this step are already correct; you just need to run them to set things up.\n",
        "\n",
        "This code block imports all the necessary python libraries so that we can use them later:"
      ],
      "metadata": {
        "id": "VrHQqUocoCIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqzIAgYMMghQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import requests, io\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import json\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block downloads a list of class labels that will be handy in the future:"
      ],
      "metadata": {
        "id": "ap2tEwIxoKrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1GpzV817YM1-1tqglgsUVISbtcgitvzbP?usp=share_link -O ./data --folder"
      ],
      "metadata": {
        "id": "F6t4_xH3uZZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block creates a \"visualize\" function that helps us compare the original image to the adversarial image:"
      ],
      "metadata": {
        "id": "XUsyXAsyoOoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(x, x_adv, x_grad, epsilon, clean_pred, adv_pred, clean_prob, adv_prob):\n",
        "  x = x.squeeze(0)     #remove batch dimension # B X C H X W ==> C X H X W\n",
        "  x = x.mul(torch.FloatTensor(std).view(3,1,1)).add(torch.FloatTensor(mean).view(3,1,1)) #reverse of normalization op- \"unnormalize\"\n",
        "  save_image(x, \"original.png\")\n",
        "  x = np.transpose(x.numpy(), (1,2,0))   # C X H X W  ==>   H X W X C\n",
        "  x = np.clip(x, 0, 1)\n",
        "  \n",
        "  x_adv = x_adv.squeeze(0)\n",
        "  x_adv = x_adv.mul(torch.FloatTensor(std).view(3,1,1)).add(torch.FloatTensor(mean).view(3,1,1)) #reverse of normalization op\n",
        "  save_image(x_adv, \"adversarial.png\")\n",
        "  x_adv = np.transpose( x_adv.numpy() , (1,2,0))   # C X H X W  ==>   H X W X C\n",
        "  x_adv = np.clip(x_adv, 0, 1)\n",
        "  \n",
        "  x_grad = x_grad.squeeze(0).numpy()\n",
        "  x_grad = np.transpose(x_grad, (1,2,0))\n",
        "  x_grad = np.clip(x_grad, 0, 1)\n",
        "  \n",
        "  figure, ax = plt.subplots(1,3, figsize=(18,8))\n",
        "  ax[0].imshow(x)\n",
        "  ax[0].set_title('Clean Example', fontsize=20)\n",
        "  \n",
        "  ax[1].imshow(x_grad)\n",
        "  ax[1].set_title('Perturbation', fontsize=20)\n",
        "  ax[1].set_yticklabels([])\n",
        "  ax[1].set_xticklabels([])\n",
        "  ax[1].set_xticks([])\n",
        "  ax[1].set_yticks([])\n",
        "\n",
        "  \n",
        "  ax[2].imshow(x_adv)\n",
        "  ax[2].set_title('Adversarial Example', fontsize=20)\n",
        "  \n",
        "  ax[0].axis('off')\n",
        "  ax[2].axis('off')\n",
        "\n",
        "  ax[0].text(1.1,0.5, \"+{}*\".format(round(epsilon,3)), size=15, ha=\"center\", \n",
        "            transform=ax[0].transAxes)\n",
        "  \n",
        "  ax[0].text(0.5,-0.13, \"Prediction: {}\\n Probability: {}\".format(clean_pred, clean_prob), size=15, ha=\"center\", \n",
        "        transform=ax[0].transAxes)\n",
        "  \n",
        "  ax[1].text(1.1,0.5, \" = \", size=15, ha=\"center\", transform=ax[1].transAxes)\n",
        "\n",
        "  ax[2].text(0.5,-0.13, \"Prediction: {}\\n Probability: {}\".format(adv_pred, adv_prob), size=15, ha=\"center\", \n",
        "        transform=ax[2].transAxes)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SRtbsxE6jHIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block creates a `get_image` function that gets an image from a URL and returns it in three different formats, two of which depend on PyTorch."
      ],
      "metadata": {
        "id": "_IChlHp1oXkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# When normalizing images, use this mean and standard deviation\n",
        "# (Don't change these.)\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "def get_image(url):\n",
        "  # Get image from URL\n",
        "  response = requests.get(url)\n",
        "  img = Image.open(io.BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "  # Preprocess image into desired tensor format\n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize((299,299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "  ])\n",
        "\n",
        "  img_tensor = preprocess(img)\n",
        "  img_tensor = img_tensor.unsqueeze(0) # add batch dimension (C*H*W => B*C*H*W)\n",
        "\n",
        "  img_variable = Variable(img_tensor, requires_grad=True)\n",
        "\n",
        "  return (img, img_tensor, img_variable)"
      ],
      "metadata": {
        "id": "dCDYLhrcwJ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you have run all 4 of these code blocks before moving on to the next step."
      ],
      "metadata": {
        "id": "95p6Tex1oixI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: View ImageNet Gallery\n",
        "\n",
        "We are going to be attacking the Inception v3 model, which was trained by Google to classify images into one of 1,000 different categories. The model was trained using a dataset called \"ImageNet\" which is a huge collection of millions of images, each pre-categorized into those 1,000 classes.\n",
        "\n",
        "The following gallery shows one example image from the ImageNet dataset for each of the 1,000 classes so that you can see what all the different classes are.\n",
        "\n",
        "Open the gallery and spend some time exploring the dataset:\n",
        "\n",
        "https://github.com/PullJosh/imagenet-sample-images/blob/master/gallery.md#gallery-of-imagenet-sample-images"
      ],
      "metadata": {
        "id": "Vs31Bk6K7Ors"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Download & Test the \"Inception v3\" Model"
      ],
      "metadata": {
        "id": "724e4rKgqfLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3A: Download the model"
      ],
      "metadata": {
        "id": "X2fBzYymv_kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're using someone else's pre-trained model, we can just download it! (We don't need to train the model ourselves.) Run the following code block to download the model."
      ],
      "metadata": {
        "id": "F-XHHdSRpSje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Inception v3 model, pre-trained so that\n",
        "# it works right out of the box.\n",
        "inceptionv3 = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
        "\n",
        "# Set the model to \"evaluation\" mode, because we want to *use*\n",
        "# the model, not train it.\n",
        "inceptionv3.eval()\n",
        "\n",
        "print(\"Model downloaded!\")"
      ],
      "metadata": {
        "id": "1lZmLW7eM8dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3B: Download the label names"
      ],
      "metadata": {
        "id": "3pCPZCF-wCOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model classifies images into one of 1,000 different classes. Each class has a name (\"label\"), but we have to download them ourselves. The following code block stores the labels in the `label` variable and prints them out.\n",
        "\n",
        "**You should be able to see that the label numbers correspond to the numbers shown in [the gallery](https://github.com/PullJosh/imagenet-sample-images/blob/master/gallery.md#gallery-of-imagenet-sample-images).**"
      ],
      "metadata": {
        "id": "6tNFGOTWtw5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/labels.json\", \"r\") as file:\n",
        "  # Get the labels from the file\n",
        "  labels = json.load(file)\n",
        "  \n",
        "  # Convert label indicies from strings to numbers\n",
        "  labels = {int(index):label for index, label in labels.items()}\n",
        "\n",
        "print(\"Labels:\", labels)"
      ],
      "metadata": {
        "id": "icnZVhdBIuAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3C: Get an image from the internet"
      ],
      "metadata": {
        "id": "m_ow9JMDwMK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part is fun! We need an image to classify, so we will download one from the internet. The following code grabs an image from a URL and then displays it.\n",
        "\n",
        "**You can change the image URL if you want! Just make sure you choose something that the AI will be able to classify (it needs to belong to one of the 1,000 different classes.)** And it's best *NOT* to use one of the training images, so don't take one directly from the gallery. Use Google Images instead."
      ],
      "metadata": {
        "id": "zyw6IM6GuOuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img, img_tensor, img_variable) = get_image(\"https://i.imgur.com/AcVntvT.png\")\n",
        "img # Show image"
      ],
      "metadata": {
        "id": "-YIeXliGNXdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3D: Ask the model to classify the image"
      ],
      "metadata": {
        "id": "Elvq07IewOBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's pass our image into the `inceptionv3` model and see what the output is:"
      ],
      "metadata": {
        "id": "nIjGDasduvSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get neural network's predictions for this image\n",
        "output = inceptionv3.forward(img_variable)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "b9To1_C9PodY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the model gives a huge list of 1,000 numbers as output. Each of the 1,000 numbers corresponds to one of the classes, and a large positive value means the model thinks this class is a good fit for your image. A negative number means the model thinks it's a bad fit.\n",
        "\n",
        "Let's convert these positive and negative numbers into a probability distribution, which is 1,000 numbers that are all between 0 and 1 (corresponding to 0% likelihood or 100% likelyhood)."
      ],
      "metadata": {
        "id": "w-piBD2Nu-FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert output to a probability distribution using softmax\n",
        "# (The probability distribution tells you how likely it is that\n",
        "# the image belongs to each of the 1000 different classes.)\n",
        "output_probs = F.softmax(output, dim=1)\n",
        "\n",
        "print(output_probs)"
      ],
      "metadata": {
        "id": "2cwUpXvXu3TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, these numbers are all positive now. (Although most are scaled to be extremely small... like $10^{-5}$ small.)\n",
        "\n",
        "Finally, we can figure out the best class for the image by finding which class has the highest probability. The following code does that:"
      ],
      "metadata": {
        "id": "1tTahGnUvXbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of the most likely class (the predicted label for this image)\n",
        "label_index = int(torch.argmax(output_probs))\n",
        "label = labels[label_index]\n",
        "\n",
        "# Get probability of most likely class\n",
        "pred_prob = float(output_probs[0][label_index])\n",
        "\n",
        "print(f\"I predict with {round(pred_prob * 100, 2)}% confidence that this image belongs to class {label_index} ({label})\")"
      ],
      "metadata": {
        "id": "wXecJ8pCvWse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you stuck with the original cat image we gave you, it should say 74.89% confidence that the image belongs to class 282 (tiger cat).\n",
        "\n",
        "If you chose your own image, hopefully the output you got seems reasonable."
      ],
      "metadata": {
        "id": "NpyIgE7LvpXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: Move Away from the Correct Answer\n",
        "\n",
        "Remember, in Method 1 we are going to *increase* the loss of the model, because that means it will be less accurate at classifying the image.\n",
        "\n",
        "The gradient tells us how to adjust each pixel in order to increase the loss, as seen here:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://miro.medium.com/max/1400/1*jR_MrEHPtGlcn1PRvxN6xw.jpeg\" width=\"400px\" />\n",
        "</center>\n",
        "\n",
        "That's exactly what we're about to do."
      ],
      "metadata": {
        "id": "VxjM0yAdoGwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1A: Set the `target` to move AWAY from"
      ],
      "metadata": {
        "id": "567l4QdEvl-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the target to be 282 (tiger cat), because that's the\n",
        "# CORRECT classification of the input image. (We will try\n",
        "# to make the model predict anything OTHER than tiger cat.)\n",
        "\n",
        "# TODO: If you are using a different image, change this number to\n",
        "# be the CORRECT classification of that image.\n",
        "target = Variable(torch.LongTensor([282]), requires_grad=False)\n",
        "print(target)"
      ],
      "metadata": {
        "id": "xBnGXx_Xiovi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1B: Calculate the loss & gradient based on the chosen target"
      ],
      "metadata": {
        "id": "yT2C3m-nvqvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code computes the gradient for the entire network. In particular, we care that it computes the gradient for the input image."
      ],
      "metadata": {
        "id": "YvpdmWdE-RTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The loss function for the model is called Cross Entropy Loss\n",
        "# and it is used when you're classifying something\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# In this case, the calculated loss should measure the difference\n",
        "# between what the model predicted and the correct output value `target`\n",
        "# which we just specified.\n",
        "loss_cal = loss(output, target)\n",
        "\n",
        "# Calculate the gradients for everything (including the input image,\n",
        "# which is what we care about) in terms of this loss function.\n",
        "if img_variable.grad is not None:\n",
        "  img_variable.grad.zero_() # Flush (reset) gradients first if needed\n",
        "loss_cal.backward(retain_graph=True)"
      ],
      "metadata": {
        "id": "hjohH7DXivo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1C: Generate the adversarial image"
      ],
      "metadata": {
        "id": "8oixycHWvwM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the gradient computed, we're ready to adjust the input image.\n",
        "\n",
        "The variables at your disposal are `img_variable.data`, `epsilon`, and `gradient`. You want to set `adv_img_tensor` to be the adversarial image. Can you find the simple equation to do this? **Edit the code below with your equation.**\n",
        "\n",
        "![Slide screenshot](https://i.imgur.com/tSnryEX.png)"
      ],
      "metadata": {
        "id": "6r2hafTw-14o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.02\n",
        "\n",
        "# Get the computed gradient for the input image\n",
        "gradient = torch.sign(img_variable.grad.data)\n",
        "\n",
        "# TODO: Generate the adversarial image using\n",
        "# img_variable.data, epsilon, and gradient.\n",
        "# You should fill this in using a very simple equation\n",
        "# with just those three variables.\n",
        "adv_img_tensor = # ???"
      ],
      "metadata": {
        "id": "FsgNwm1hi3RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully your `adv_img_tensor` is correct! We'll find out in the next step."
      ],
      "metadata": {
        "id": "dq3r6VoPAG7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1D: Ask the model to classify the adversarial image"
      ],
      "metadata": {
        "id": "_o7NRxt8vybW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code is incomplete!** In step 3D we asked the model to classify the original image. Now we want to ask it to classify the adversarial image, `adv_img_variable`. Using step 3D as a reference, can you fill in all the `# ???` spaces in the code?\n",
        "\n",
        "Once you do it successfully, you'll be able to see what the model thinks of your adversarial image vs. the input image."
      ],
      "metadata": {
        "id": "L8LwwZGPAQy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get neural network's predictions for this adversarial image\n",
        "adv_img_variable = Variable(adv_img_tensor)\n",
        "adv_output = # ???\n",
        "\n",
        "adv_output_probs = # ???\n",
        "\n",
        "adv_label_index = # ???\n",
        "adv_label = # ???\n",
        "\n",
        "adv_pred_prob = # ???\n",
        "\n",
        "print(f\"I predict with {round(pred_prob * 100, 2)}% confidence that the original image belongs to class {label_index} ({label})\")\n",
        "print(f\"I predict with {round(adv_pred_prob * 100, 2)}% confidence that the newly-generated adversarial image belongs to class {adv_label_index} ({adv_label})\")\n",
        "print()\n",
        "\n",
        "visualize(img_tensor, adv_img_tensor, gradient, epsilon, label, adv_label, pred_prob, adv_pred_prob)"
      ],
      "metadata": {
        "id": "H_v-bjCCroTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully you were able to successfully trick the model into making the wrong prediction.\n",
        "\n",
        "As a final summary of what we did, take a look at this image:\n",
        "\n",
        "![]()"
      ],
      "metadata": {
        "id": "yXNu5rKoEwhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: Move Toward a Specific \"Target\" Wrong Answer"
      ],
      "metadata": {
        "id": "0xoo6ERmj98Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2A: Set the target to move TOWARD"
      ],
      "metadata": {
        "id": "MxnfBF9LwsJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's decision time!** With method 2, you get to choose what output label you want to trick the model into believing. We've included 288 (leopard) as a default, but you can change it to anything you want. Refer to the [ImageNet gallery](https://github.com/PullJosh/imagenet-sample-images/blob/master/gallery.md#gallery-of-imagenet-sample-images) for a reminder of which number corresponds to which label. Choose your favorite and put it in the code!"
      ],
      "metadata": {
        "id": "2YqM_bZuA0Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the target to be 288 (leopard), because that's the\n",
        "# TARGET classification that we want to trick the model\n",
        "# into believing.\n",
        "\n",
        "# You can choose any target you want! Ideally the computer\n",
        "# will be able to generate an adversarial image that tricks\n",
        "# the model into believing that this is the correct output class.\n",
        "target = Variable(torch.LongTensor([288]), requires_grad=False)\n",
        "print(target)"
      ],
      "metadata": {
        "id": "3GDxBjPaj_vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2B: Calculate the loss & gradient based on the chosen target"
      ],
      "metadata": {
        "id": "3L5G7OhuxrV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like in Method 1, we're going to compute the gradient of the loss function. But this time, it's the loss based on the target you chose above, which means that in step 2C we will want to *decrease* the loss rather than increase it.\n",
        "\n",
        "**This code is already correct. You just need to run it.**"
      ],
      "metadata": {
        "id": "1AmPjPfqBO0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this case, the calculated loss should measure the difference\n",
        "# between what the model predicted and the correct output value `target`\n",
        "# which we just specified.\n",
        "loss_cal = loss(output, target)\n",
        "\n",
        "# Calculate the gradients for everything (including the input image,\n",
        "# which is what we care about) in terms of this loss function.\n",
        "if img_variable.grad is not None:\n",
        "  img_variable.grad.zero_() # Flush (reset) gradients first if needed\n",
        "loss_cal.backward(retain_graph=True)"
      ],
      "metadata": {
        "id": "1NX9U9bHkBy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2C: Generate the adversarial image"
      ],
      "metadata": {
        "id": "HAp4aED3yCoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aha! Time to generate the adversarial image. This is very similar to Method 1C, but this time we want to *decrease* the loss rather than increase it, which means that we need to do the *opposite* of what the gradient tells us to do.\n",
        "\n",
        "**You should insert an equation here that is similar to what you did in 1C, but updated to go *against* the gradient rather than with it.**"
      ],
      "metadata": {
        "id": "Jq8NE7aUBceE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.02\n",
        "\n",
        "# Get the computed gradient for the input image\n",
        "gradient = torch.sign(img_variable.grad.data)\n",
        "\n",
        "# TODO: Generate the adversarial image using\n",
        "# img_variable.data, epsilon, and gradient.\n",
        "# (Remember that this time you want to MINIMIZE the loss,\n",
        "# moving closer to the target)\n",
        "adv_img_tensor = # ???\n",
        "\n",
        "print(gradient)"
      ],
      "metadata": {
        "id": "Enr9SmfTyGFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2D: Ask the model to classify the adversarial image"
      ],
      "metadata": {
        "id": "B9ozT3VMzJmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, we have generated an adversarial image and are ready to see what the model thinks.\n",
        "\n",
        "**This code is already complete.** Run it to see the model's prediction. Did you trick the model?\n",
        "\n",
        "**Then, try this method again but with a different chosen target in Method 2A.** Does it give you the output you wanted? Does it not? These things don't always work, but you should be able to play around with it and get a nice result eventually."
      ],
      "metadata": {
        "id": "YnI-LJVOBz5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get neural network's predictions for this adversarial image\n",
        "adv_img_variable = Variable(adv_img_tensor)\n",
        "adv_output = inceptionv3.forward(adv_img_variable)\n",
        "\n",
        "adv_output_probs = F.softmax(adv_output, dim=1)\n",
        "\n",
        "adv_label_index = int(torch.argmax(adv_output_probs))\n",
        "adv_label = labels[adv_label_index]\n",
        "\n",
        "adv_pred_prob = float(adv_output_probs[0][adv_label_index])\n",
        "\n",
        "print(f\"I predict with {round(pred_prob * 100, 2)}% confidence that the original image belongs to class {label_index} ({label})\")\n",
        "print(f\"I predict with {round(adv_pred_prob * 100, 2)}% confidence that the newly-generated adversarial image belongs to class {adv_label_index} ({adv_label})\")\n",
        "print()\n",
        "\n",
        "visualize(img_tensor, adv_img_tensor, gradient, epsilon, label, adv_label, pred_prob, adv_pred_prob)"
      ],
      "metadata": {
        "id": "a22k7UsLyfcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 3: Iteratively Move Toward a Specific Wrong Answer"
      ],
      "metadata": {
        "id": "irKVC_Wulp1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3A: Set the target to move TOWARD"
      ],
      "metadata": {
        "id": "g-XC7PN-bxr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like in method 2, you can choose whatever target you want and the computer will try to produce an image that the model classifies as the target you set."
      ],
      "metadata": {
        "id": "l-BZvyEUCL-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose whatever target you want! 9 is ostrich.\n",
        "target = Variable(torch.LongTensor([9]), requires_grad=False)"
      ],
      "metadata": {
        "id": "_-GRA3tLlqtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3B: Iteratively calculate the gradient & apply it to the image many times"
      ],
      "metadata": {
        "id": "ZCLQtv_li1rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step works just like 2B & 2C, but it performs multiple nudges iteratively to get a better result.\n",
        "\n",
        "**We've completed the code for you because it's pretty annoying to do yourself.** Writing this code requires a bit of battling against PyTorch to make sure all the gradients are calculated correctly, and it's not super fun. Definitely try to understand it though!\n",
        "\n",
        "**However, there are things to tweak!** Try changing `epsilon`, `num_steps`, and `alpha` and watch how your results change."
      ],
      "metadata": {
        "id": "_YxAwT0uCYG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In past methods, we have left img_variable as is and\n",
        "# created a new output variable called adv_img_variable\n",
        "# containing our output tensor.\n",
        "\n",
        "# This time, since we're using an iterative method, we will\n",
        "# repeatedly edit the contents of img_variable to make it\n",
        "# more and more like to be classified as the desired `target`\n",
        "\n",
        "# In case you run this cell multiple times, reset img_variable\n",
        "# to its initial value before any changes were made to it:\n",
        "img_variable.data = img_tensor\n",
        "\n",
        "epsilon = 0.25\n",
        "num_steps = 5\n",
        "alpha = 0.025\n",
        "\n",
        "for i in range(num_steps):\n",
        "  # Reset gradient\n",
        "  if img_variable.grad is not None:\n",
        "    img_variable.grad.zero_()\n",
        "\n",
        "  # Classify this work-in-progress image\n",
        "  output = inceptionv3.forward(img_variable)\n",
        "\n",
        "  # Compute the loss value compared to the target output we're aiming for\n",
        "  loss = torch.nn.CrossEntropyLoss()\n",
        "  loss_cal = loss(output, target)\n",
        "  loss_cal.backward()\n",
        "\n",
        "  # Update the image based on the gradient\n",
        "  x_grad = alpha * torch.sign(img_variable.grad.data)\n",
        "  adv_temp = img_variable.data - x_grad\n",
        "  total_grad = adv_temp - img_tensor\n",
        "  total_grad = torch.clamp(total_grad, -epsilon, epsilon)\n",
        "  x_adv = img_tensor + total_grad\n",
        "  img_variable.data = x_adv"
      ],
      "metadata": {
        "id": "tGtQ6u7IlwT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3C: Ask the model to classify the adversarial image"
      ],
      "metadata": {
        "id": "FbvyK6q_m3c-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, we can ask the model to classify the generated image and see what it thinks."
      ],
      "metadata": {
        "id": "SZe2gEitCzu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_adv = inceptionv3.forward(img_variable)\n",
        "x_adv_pred = labels[int(torch.max(output_adv.data, 1)[1][0])]\n",
        "output_adv_probs = F.softmax(output_adv, dim=1)\n",
        "x_adv_pred_prob = (torch.max(output_adv_probs.data, 1)[0][0]) * 100\n",
        "visualize(img_tensor, img_variable.data, total_grad, epsilon, label, x_adv_pred, pred_prob, x_adv_pred_prob)"
      ],
      "metadata": {
        "id": "QnuLshmjl0ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Reading\n",
        "\n",
        "[Pytorch Adversarial Attack Tutorials](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)\n",
        "If you want to work at your own pace at hands on examples of adversarial attacks, check out this series of tutorials\n",
        "\n",
        "[Ian Goodfellow Presents Adversarial Examples (video)](https://www.youtube.com/watch?v=CIfsB_EYsVI)\n",
        "Learn more about FGSM as well as alternative attacks. He talks about the broader implications of Adversarial Attacks."
      ],
      "metadata": {
        "id": "Qjz9L-7xNk05"
      }
    }
  ]
}